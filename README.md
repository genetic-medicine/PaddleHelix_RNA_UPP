# èºæ—‹æ¡¨RNAç»“æ„é¢„æµ‹ç«èµ›ç¬¬ä¸€åæ–¹æ¡ˆ

## ç«èµ›è¦æ±‚
åŸºäºç™¾åº¦å‘å¸ƒçš„RNAäºŒçº§ç»“æ„é¢„æµ‹ç®—æ³•LinearFoldå’ŒRNAé…åˆ†æ–¹ç¨‹ç®—æ³•LinearPartitionï¼Œé¢„æµ‹ç»™å®šRNAåºåˆ—åœ¨æ¯ä¸ªä½ç‚¹ä¸Šä¿æŒä¸æˆå¯¹çš„æ¦‚ç‡.

è¯¦ç»†è¯·è§ï¼š https://aistudio.baidu.com/aistudio/competition/detail/61

aistudioæºä»£ç å…¬å¼€: https://aistudio.baidu.com/aistudio/projectdetail/1479469

## ç”Ÿç‰©åŸºç¡€ ## 
*æ³¨: å¦‚æœ‰ç”Ÿç‰©èƒŒæ™¯,è¯·è·³è¿‡æœ¬èŠ‚*

æ‰€æœ‰å¯ä»¥ç§°ä¸ºç”Ÿå‘½ä½“çš„ç³»ç»Ÿï¼Œæ— è®ºç®€å•æˆ–å¤æ‚ï¼Œæ— ä¸€ä¾‹å¤–åœ°ä»¥æ ¸é…¸ä¸ºé—ä¼ ç‰©è´¨ã€‚æ ¸é…¸ä¸»è¦åˆ†ä¸ºè„±æ°§æ ¸ç³–æ ¸é…¸(DNA)å’Œæ ¸ç³–æ ¸é…¸(RNA)ä¸¤å¤§ç±»ï¼Œæ¯ç±»æ ¸é…¸éƒ½æ˜¯ç”±å››ç§ä¸åŒçš„å•å…ƒï¼ˆç§°ä¸ºç¢±åŸºï¼‰ä»¥çº¿æ€§çš„å½¢å¼è¿æ¥æˆä¸€ä¸ªé•¿é“¾ï¼Œå®ƒä»¬çš„æ’åˆ—é¡ºåºå°±æ˜¯æˆ‘ä»¬æ‰€è¯´çš„åŸºå› åºåˆ—ã€‚æ ¸é…¸åœ¨è‡ªç„¶ç•Œä¸­çš„é‡è¦åœ°ä½æ¯‹åº¸ç½®ç–‘ï¼Œç”šè‡³äºæ— è‡ªæˆ‘ç¹æ®–èƒ½åŠ›çš„ç—…æ¯’ä¹Ÿæ˜¯ä»¥æ ¸é…¸ä½œä¸ºåŸºå› ï¼Œæ¯”å¦‚æ­£åœ¨å…¨ä¸–ç•Œè‚†è™çš„æ–°å† ç—…æ¯’çš„åŸºå› æ˜¯å¤§çº¦3ä¸‡ä¸ªç¢±åŸºé•¿çš„å•é“¾RNA. æœ‰äº›åŸºå› èƒ½å¤Ÿç¼–ç ç‰¹å¼‚çš„è›‹ç™½ï¼Œæˆ‘ä»¬ç§°è¿™äº›ä¸ºç¼–ç åŸºå› . åˆ†å­ç”Ÿç‰©å­¦çš„ä¸­å¿ƒæ³•åˆ™æè¿°äº†ä»åŸºå› åˆ°è›‹ç™½çš„è¿‡ç¨‹: DNAå…ˆè¢«è½¬å½•ä¸ºä¿¡ä½¿RNA (mRNA), ç„¶åmRNAè¢«ç¿»è¯‘ä¸ºè›‹ç™½ã€‚ä½†ç¼–ç åŸºå› åªå äº†åŸºå› ç»„çš„ä¸€å°éƒ¨åˆ†(~2%)ï¼Œå¤§éƒ¨åˆ†è¢«è½¬å½•çš„RNAæ˜¯éç¼–ç RNAã€‚

RNAæ˜¯æœ¬æ¬¡èºæ—‹æµ†ç»“æ„é¢„æµ‹ç«èµ›çš„ä¸»è§’ã€‚ç«èµ›è¦æ±‚ç”¨æ·±åº¦å­¦ä¹ çš„æ–¹æ³•é¢„æµ‹æ¯ä¸ªç¢±åŸºçš„ä¸é…å¯¹å‡ ç‡ã€‚ ä½œä¸ºä¸€ä¸ªçº¿æ€§çš„é“¾çŠ¶å¤§åˆ†å­ï¼ŒRNAå…·æœ‰éå¸¸é«˜çš„æŸ”æ€§ï¼Œ æ˜“äºå¼¯æ›²ï¼Œ å¥½æ¯”ä¸€æ¡ç»†é•¿çš„çº¿ã€‚ å¦‚æœç¢±åŸºä¹‹é—´æ²¡æœ‰ä»»ä½•ç›¸äº’ä½œç”¨ï¼ŒRNAåœ¨ä¸‰ç»´ç©ºé—´é‡Œå°±ä¼šæ‚ä¹±æ— ç« æ¯«æ— ç»“æ„è€Œè¨€ã€‚å¯ä½œä¸ºç”Ÿç‰©å¤§åˆ†å­çš„RNAéœ€è¦å…·æœ‰ç‰¹å®šç»“æ„æ‰èƒ½è¡Œä½¿å…¶ç”Ÿç‰©åŠŸèƒ½, å› è€Œç¢±åŸºé—´æ˜¯å¦é…å¯¹å’Œå¦‚ä½•é…å¯¹è‡³å…³é‡è¦.

RNAä¸»è¦ç”±å››ç§ç¢±åŸºç»„æˆï¼Œè™½ç„¶æˆ‘ä»¬æœ€ç†Ÿæ‚‰çš„æ˜¯ä¸¤ç§ç¢±åŸºå¯¹ç±»å‹, çœŸå®çš„æƒ…å†µæ˜¯ç¢±åŸºæœ‰å¾ˆå¤šé…å¯¹çš„æ–¹å¼. æ¯ä¸ªç¢±åŸºæœ‰ä¸‰ä¸ªè¾¹å¯ä»¥é…å¯¹ï¼Œå†åŠ ä¸Šç³–è‹·é”®çš„ç©ºé—´å–å‘ï¼Œä¸¤ä¸ªç¢±åŸºé—´å°±æœ‰12ç§ä¸åŒçš„é…å¯¹æ–¹å¼, å…¨éƒ¨ä¸€èµ·æœ‰è¶…è¿‡30ç§ä¸åŒçš„ç¢±åŸºä¸¤ä¸¤é…å¯¹ç»„åˆ(è¿™é‡Œä¸è€ƒè™‘æ¦‚ç‡æå°çš„ä¸¤ä¸ªä»¥ä¸Šç¢±åŸºçš„é…å¯¹)ã€‚æ‰€ä»¥å¯¹äºä¸€ä¸ªRNAåºåˆ—, å…¶å¯èƒ½çš„é…å¯¹æ–¹å¼æ˜¯ä¸€ä¸ªå·¨å¤§çš„æ’åˆ—ç»„åˆç©ºé—´ã€‚ ç¢±åŸºä¹‹é—´é…å¯¹çš„æºé©±åŠ¨åŠ›æ¥è‡ªäºç¢±åŸºä¹‹é—´çš„å¸å¼•åŠ›(ç›´æ¥æˆ–é—´æ¥)ï¼Œæœ€ä¸»è¦çš„æ–¹å¼æ˜¯æ°¢é”®ã€‚æ¯ä¸€ä¸ªç¢±åŸºå’Œå…¶å®ƒç¢±åŸºéƒ½å­˜åœ¨æˆ–å¼ºæˆ–å¼±çš„å¸å¼•åŠ›ï¼Œä½†æ˜¯åªèƒ½å’Œå…¶ä¸­ä¸€ä¸ªé…å¯¹ï¼Œæ‰€ä»¥å®ƒä»¬ç›¸äº’ç«äº‰, æœ€ä¼˜çš„é…å¯¹ç»„åˆèƒ½æœ€å¤§åŒ–ç¢±åŸºä¹‹é—´çš„å¸å¼•ä½œç”¨, ä»çƒ­åŠ›å­¦è§’åº¦ä¸Šè¯´è‡ªç”±èƒ½æœ€å°åŒ–. åŒæ—¶å¾€å¾€æœ‰å¾ˆå¤šé…å¯¹ç»„åˆæœ‰ç›¸è¿‘çš„èƒ½é‡, å¹¶ä¸å­˜åœ¨ä¸€ä¸ªå•ä¸€çš„ç¨³å®šç»“æ„, è€Œæ˜¯æœ‰å¾ˆå¤šäºšç¨³å®šç»“æ„. è¿™æ—¶å€™ä¸€ä¸ªéå¸¸æœ‰æ„ä¹‰çš„ç¢±åŸºç‰¹æ€§å°±æ˜¯å®ƒåœ¨è¿™äº›ç»“æ„é›†é‡Œçš„ä¸é…å¯¹å‡ ç‡(æˆ–è€…é…å¯¹å‡ ç‡).

## èµ›é¢˜è¯´æ˜ ##
### æŠ€æœ¯åŸºç¡€ ###
ç™¾åº¦èºæ—‹æ¡¨å›¢é˜Ÿè¿‘å¹´æ¥åœ¨RNAç»“æ„é¢„æµ‹ä¸Šåšå‡ºäº†é‡è¦çš„è´¡çŒ®, ç ”å‘å‡ºé€Ÿåº¦æœ€å¿«åŒæ—¶å‡†ç¡®åº¦æé«˜çš„ä¸€ç³»åˆ—çº¿æ€§ç®—æ³•, åšåˆ°äº†å¯¹RNAäºŒçº§ç»“æ„çš„ç›´æ¥é¢„æµ‹å’Œæ¯”å¯¹(LinearFold[1]), å¯¹ç¢±åŸºé…åˆ†å’Œé…å¯¹å‡ ç‡çš„é¢„æµ‹(LinearPartition[2]), å’Œå¯¹RNAåºåˆ—çš„è®¾è®¡ä¼˜åŒ–(LinearDesign[3]).  è¿™æ¬¡æ¯”èµ›ä¸»è¦æ˜¯åŸºäºèºæ—‹æ¡¨å›¢é˜Ÿçš„LinearFoldå’ŒLinearPartitionç®—æ³•ï¼Œç”¨æ·±åº¦å­¦ä¹ çš„æ–¹æ³•æ¥é¢„æµ‹RNAçš„ä¸é…å¯¹å‡ ç‡. 

åœ¨LinearDesignæ–‡ç« é‡Œå¯¹ç¢±åŸºä¸é…å¯¹å‡ ç‡çš„æ„ä¹‰æœ‰å¾ˆå¥½çš„è¯¦è¿°, æ‹¿mRNAç–«è‹—ä¸ºä¾‹, å¦‚æœmRNAåºåˆ—é‡Œå¤§éƒ¨åˆ†ç¢±åŸºæœ‰å¾ˆå°çš„ä¸é…å¯¹å‡ ç‡, é‚£è¯´æ˜è¿™æ˜¯ä¸€ä¸ªç¨³å®šçš„äºŒç»´ç”šè‡³ä¸‰ç»´RNAç»“æ„. ç¨³å®šçš„ç»“æ„ä¼šå¤§å¤§å»¶é•¿å…¶åœ¨ç»†èƒå†…çš„å¯¿å‘½,ä»è€Œæé«˜è›‹ç™½çš„äº§é‡. å¦‚æœå¤§éƒ¨åˆ†ç¢±åŸºæœ‰éå¸¸å¤§çš„ä¸é…å¯¹å‡ ç‡, é‚£è¯´æ˜è¿™æ˜¯ä¸€ä¸ªéå¸¸æ— ç»“æ„æˆ–åŠ¨æ€çš„RNA. è¿™ä¼šè®©mRNAåœ¨æº¶æ¶²ä¸­æ˜“äºè¢«æ°´è§£, é™ä½å…¶ç¨³å®šæ€§å’Œå¯¿å‘½, ä¸åˆ©äºè¿è¾“,å‚¨è—,ç¿»è¯‘ç­‰ç­‰. æ‰€ä»¥ç¢±åŸºä¸é…å¯¹å‡ ç‡å¯¹RNAåºåˆ—è®¾è®¡æœ‰æå…¶é‡è¦çš„å®šé‡æŒ‡å¯¼æ„ä¹‰.

### è®­ç»ƒæ•°æ®åˆ†æ ###

è®­ç»ƒæ•°æ®é›†ä¸€å…±4750ä¸ªRNAåºåˆ—ï¼Œ éªŒè¯é›†250ä¸ªåºåˆ—, æµ‹è¯•é›†112ä¸ªåºåˆ—ï¼Œå®ƒä»¬çš„é•¿åº¦åˆ†å¸ƒå¦‚å›¾ä¸€æ‰€ç¤º. è®­ç»ƒå’ŒéªŒè¯é›†é•¿åº¦åœ¨100 å’Œ500ç¢±åŸºä¹‹é—´, åˆ†å¸ƒç›¸å¯¹å‡åŒ€ï¼Œå¯æ˜¯æµ‹è¯•é›†é‡Œæœ‰è¾ƒé•¿çš„åºåˆ—ï¼Œå°¤å…¶è¶…è¿‡30%çš„åºåˆ—çš„é•¿åº¦500ä»¥ä¸Šï¼Œè¿™ç»™é¢„æµ‹å¢åŠ äº†éš¾åº¦ã€‚å¦‚æœæŒ‰ç…§ç¢±åŸºè®¡ç®—ï¼Œè®­ç»ƒå’ŒéªŒè¯é›†ä¸€å…±æœ‰1,562,736ä¸ªç¢±åŸº(åºåˆ—å¹³å‡é•¿åº¦313ç¢±åŸº)ï¼Œæµ‹è¯•é›†ä¸€å…±æœ‰49,279ç¢±åŸºï¼ˆåºåˆ—å¹³å‡é•¿åº¦440ç¢±åŸºï¼‰ã€‚ 

![å›¾ä¸€](https://ai-studio-static-online.cdn.bcebos.com/1785b0ba9f464b85a36211a9d8cc44e2012a563dbff641aabb6f4c683f74314a)

å›¾è¡¨ 1: è®­ç»ƒ(è“),éªŒè¯(çº¢)å’Œæµ‹è¯•(ç»¿)é›†RNAåºåˆ—çš„é•¿åº¦åˆ†å¸ƒ.

åŸºäºæä¾›çš„åºåˆ—, æˆ‘ä»¬ç”¨LinearFoldè®¡ç®—äºŒçº§ç»“æ„å’Œç”¨LinearPartitionè®¡ç®—ä¸é…å¯¹å‡ ç‡ã€‚è¿™äº›è®¡ç®—çš„ç»“æœå¯ä»¥è½¬æ¢æˆç¢±åŸºä¸é…å¯¹å‡ ç‡, æ¯”å¦‚LinearFoldçš„äºŒçº§ç»“æ„å¯è½¬æ¢ä¸ºäºŒè¿›åˆ¶çš„ä¸é…å¯¹å‡ ç‡(0æˆ–1). LinearFoldå¯¹è®­ç»ƒï¼ŒéªŒè¯å’Œæµ‹è¯•é›†é¢„æµ‹çš„ç¢±åŸºä¸é…å¯¹å‡ ç‡åˆ†å¸ƒå¤§ä½“ä¸€è‡´ï¼Œçº¦62%çš„ç¢±åŸºæ˜¯é…å¯¹çš„ï¼Œå…¶ä½™38%ä¸é…å¯¹. LinearPartitionæ‰€é¢„æµ‹çš„ä¸é…å¯¹å‡ ç‡æ˜¯ä¸€ä¸ªè¿ç»­ç©ºé—´ï¼Œå…¶åˆ†å¸ƒå¦‚å›¾äºŒæ‰€ç¤ºã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸‰ä¸ªæ•°æ®é›†çš„å‡ ç‡åˆ†å¸ƒç›¸å·®ä¸å¤šï¼Œæœ€çªå‡ºçš„ç‰¹å¾æ˜¯å‡ ç‡åˆ†å¸ƒéå¸¸ä¸å‡åŒ€, å°¤å…¶æœ‰ä¸¤ä¸ªåˆ†å¸ƒå³°åˆ†åˆ«åœ¨0å’Œ1é™„è¿‘, è¯´æ˜å³ä½¿åœ¨è¿ç»­ç©ºé—´é‡Œå¤§å¤šæ•°ç¢±åŸºçš„é…å¯¹å‡ ç‡é›†ä¸­åœ¨0æˆ–1é™„è¿‘. ä¸ºäº†èƒ½ç›´æ¥æ¯”è¾ƒLinearFoldå’ŒLinearPartition, æˆ‘ä»¬å¯ä»¥æŠŠLinearPartitionçš„è¿ç»­ç©ºé—´äºŒè¿›åˆ¶åŒ– (0.0-0.5ä¸º0, 0.5-1.0ä¸º1ï¼‰ï¼Œè¿™æ ·å¾—åˆ°ï½55%çš„ç¢±åŸºä¸é…å¯¹å‡ ç‡ä¸º0ï¼Œ å’ŒLinearFoldé¢„æµ‹çš„62%æœ‰ä¸€äº›å·®è·. 

![](https://ai-studio-static-online.cdn.bcebos.com/c8d6c171d7a44f2e9bca418c22f336d323df11c6c4644cd7944ee98f793a67dd)

å›¾è¡¨ 2: LinearPartitioné¢„æµ‹çš„ç¢±åŸºä¸é…å¯¹å‡ ç‡åˆ†å¸ƒ: è®­ç»ƒ(è“), éªŒè¯(çº¢)å’Œæµ‹è¯•(ç»¿)é›†.

è®­ç»ƒå’ŒéªŒè¯é›†é‡Œçš„æ ‡æ³¨æ•°æ®æ˜¯æ¯ä¸ªç¢±åŸºçš„ä¸é…å¯¹å‡ ç‡ã€‚å›¾ä¸‰å±•ç¤ºäº†èšé›†äº†æ‰€æœ‰åºåˆ—ç¢±åŸºä¸é…å¯¹å‡ ç‡çš„åˆ†å¸ƒ, æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸é…å¯¹å‡ ç‡æˆä¸¤æåˆ†åŒ–èµ°åŠ¿ï¼Œ ç»å¤§éƒ¨åˆ†ç¢±åŸºçš„é…å¯¹æˆ–ä¸é…å¯¹çš„å‡ ç‡åœ¨95%ä»¥ä¸Šï¼Œè¿™æ¯”LinearPartitioné¢„æµ‹çš„ä¸é…å¯¹æ¦‚ç‡åˆ†å¸ƒè¦æ›´åŠ ä¸¤æåˆ†åŒ–ã€‚å€¼å¾—ä¸€æçš„æ˜¯æ ‡æ³¨æ•°æ®åœ¨äºŒè¿›åˆ¶ç¦»æ•£åŒ–åçš„åˆ†å¸ƒå’ŒLinearFoldé¢„æµ‹é«˜åº¦ä¸€è‡´ï¼Œç»™å‡ºï½60%ç¢±åŸºé…å¯¹.

![](https://ai-studio-static-online.cdn.bcebos.com/b49c78dfc040408da4f09cad92a37b0cfd102db22a854cf1b2f81d9149528206)


å›¾è¡¨ 3: è®­ç»ƒ(è“)å’ŒéªŒè¯(çº¢)é›†ç¢±åŸºä¸é…å¯¹å‡ ç‡æ ‡æ³¨åˆ†å¸ƒ

### è¯„æ¯”æŒ‡æ ‡ ###

ç¢±åŸºä¸é…å¯¹å‡ ç‡é¢„æµ‹å’Œæ ‡æ³¨çš„å·®å¼‚é‡‡ç”¨çš„æ˜¯ç»å…¸è€Œç›´è§‚çš„å‡å¹³æ–¹å·®çš„å¹³æ–¹æ ¹ï¼ˆRoot Mean Square Error, RMSE)ã€‚å¦‚å‰æ–‡æ‰€è¿°ï¼Œ æˆ‘ä»¬å¯ä»¥æŠŠLinearFoldå’ŒLinearPartitionçš„é¢„æµ‹ç»“æœè½¬æ¢ä¸ºç¢±åŸºçš„ä¸é…å¯¹å‡ ç‡ï¼Œ è¿™æ ·å¯ä»¥å…ˆå’Œæ ‡æ³¨ä½œå¯¹æ¯”ã€‚ è™½ç„¶LinearFoldç»™å‡ºç»“æœçš„æ•´ä½“åˆ†å¸ƒå’Œæ ‡æ³¨å‡ ä¹å½¢åŒï¼Œå…¶RMSEå´æœ‰ï½0.30ï¼Œ è€ŒLinearPartitionç»™å‡ºçš„RMSEç¨å°ï¼Œï½0.26. å¯è§åœ¨é¢„æµ‹è¿ç»­ç©ºé—´çš„ä¸é…å¯¹å‡ ç‡æ—¶ï¼Œ LinearPartitionæœ‰æ›´å¥½çš„è¡¨ç°ï¼Œ è™½ç„¶å…¶åˆ†å¸ƒç›®æµ‹å·®è·æ›´å¤§ã€‚ å½“ç„¶æˆ‘ä»¬è¿˜å¯ä»¥ç»§ç»­åˆ†æRMSEå’ŒRNAåºåˆ—é•¿åº¦çš„ç›¸å…³æ€§ç­‰ç­‰ï¼Œ è¿™é‡Œä¸åšè¯¦è¿°ã€‚

## æ¨¡å‹æ„å»ºå’Œè®­ç»ƒ ##

### æ¡†æ¶æ€è·¯ ###
è¿™ä¸ªæ·±åº¦å­¦ä¹ ä»»åŠ¡æ˜¯ä¸€ä¸ªå…¸å‹çš„åºåˆ—åˆ°åºåˆ—(seq2seq or seq2vec)é—®é¢˜ï¼š è¾“å…¥æ˜¯RNAçš„ç¢±åŸºåºåˆ—ï¼Œ è¾“å‡ºæ˜¯æ¯ä¸ªç¢±åŸºçš„ä¸é…å¯¹æ¦‚ç‡ã€‚é‚£ä¹ˆï¼Œä¸€ä¸ªåºåˆ—åˆ°åºåˆ—çš„æ·±åº¦å­¦ä¹ æ¨¡å‹éœ€è¦â€œå­¦åˆ°â€ç¢±åŸºä¹‹é—´ä»€ä¹ˆæ ·çš„å…³ç³»æ‰èƒ½å‡†ç¡®é¢„æµ‹RNAçš„ä¸é…å¯¹å‡ ç‡å‘¢ï¼Ÿæˆ‘ä»¬ä»ä»¥ä¸‹å‡ ä¸ªè§’åº¦è€ƒè™‘ç¢±åŸºé…å¯¹é—®é¢˜, å¹¶è®¾è®¡äº†å¯¹åº”çš„ç½‘ç»œæ¡†æ¶ã€‚

ç¬¬ä¸€ï¼Œä¸€ä¸ªç¢±åŸºçš„é…å¯¹ä¸å¦æ˜¯ç”±å…¨éƒ¨åºåˆ—æ•´ä½“å†³å®šçš„ï¼Œä»…ä»…åˆ©ç”¨åºåˆ—çš„ä»»ä½•ç‰‡æ®µçš„ä¿¡æ¯æ˜¯ä¸èƒ½å‡†ç¡®é¢„æµ‹çš„ã€‚è¿™ä¸ªç‰¹æ€§å¯ä»¥ç”¨å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰æˆ–è€…å˜å‹å™¨ï¼ˆTransformerï¼‰æ¥æè¿°ã€‚æˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªTransformerç¼–ç å™¨å±‚æ¥èµ‹äºˆæ¯ä¸ªç¢±åŸºä¸€ä¸ªå…¨å±€çš„ä¿¡æ¯ï¼Œå¯¹ä½ç½®çš„ç¼–ç ç”¨çš„æ˜¯æ­£æ—‹å’Œä½™æ—‹å‡½æ•°ã€‚
ç¬¬äºŒï¼Œç¢±åŸºçš„æ’åˆ—æ˜¯ä¸€ä¸ªæœ‰æå¼ºçº¿æ€§çš„åºåˆ—ï¼Œæ”¹å˜ç¢±åŸºé—´çš„ä»»ä½•é¡ºåºéƒ½ä¼šæˆ–å¤§æˆ–å°åœ°å½±å“å…¶ä¸é…å¯¹æ¦‚ç‡ï¼Œå³ä½¿æœ‰äº›ç¢±åŸºå˜åŒ–èƒ½ä¿æŒç¢±åŸºçš„äºŒçº§ç”šè‡³ä¸‰æçš„æœ€ç¨³å®šç»“æ„ï¼Œç¢±åŸºçš„ä¸é…å¯¹å‡ ç‡ä¹Ÿä¸ä¼šä¸æ¯«ä¸å˜ã€‚æ‰€ä»¥æˆ‘ä»¬å†³å®šåŠ å…¥ä¸€ä¸ªRNNæ¥å¼ºåŒ–ç¢±åŸºé—´çš„åºåˆ—ä¾èµ–ï¼Œ å…·ä½“å½¢å¼é‡‡ç”¨äº†ä¸€ä¸ªåŒå‘LSTMå±‚ã€‚ å¦å¤–ä¸€ä¸ªè€ƒè™‘æ˜¯Transformerç¼–ç å™¨åœ¨è®­ç»ƒæ•°æ®æœ‰é™æƒ…å†µä¸‹å¯èƒ½ä¼šè¡¨ç°ä¸ä½³ã€‚
ç¬¬ä¸‰ï¼Œç¢±åŸºé…å¯¹æœ‰è¾ƒå¼ºçš„å±€éƒ¨ç›¸å…³ï¼Œ è¦å½¢æˆç¨³å®šçš„ç¢±åŸºé…å¯¹ï¼Œ è‡³å°‘ç›¸é‚»çš„ä¸‰ä¸ªä»¥ä¸Šçš„ç¢±åŸºéƒ½é…å¯¹ï¼Œ è‡ªç„¶è¶Šå¤šçš„è¿ç»­ç¢±åŸºé…å¯¹è¶Šç¨³å®šï¼ŒåŒæ—¶åªæœ‰1-2ä¸ªè¿ç»­çš„ç¢±åŸºæœ‰å¾ˆå°çš„ä¸é…å¯¹å‡ ç‡æ˜¯ä¸å¯èƒ½çš„ã€‚ é‰´äºæ­¤ï¼Œ æˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç»´çš„å·ç§¯å±‚(Conv1D)æ¥æè¿°è¿™ç§å±€éƒ¨ç›¸å…³æ€§ã€‚ 

åŸºäºä»¥ä¸Šè®¾è®¡ç†å¿µï¼Œå¦‚å›¾å››æ‰€ç¤º, é™¤äº†è¾“å…¥åµŒå…¥å±‚å¤–, æ¨¡å‹æ¡†æ¶æœ‰ä»¥ä¸‹ç»„æˆã€‚1ï¼‰ è¾“å…¥å…¨è¿æ¥æ¨¡å—ï¼Œ2ï¼‰Transformerç¼–ç æ¨¡å—ï¼Œ 3ï¼‰åŒå‘LSTMæ¨¡å—ï¼Œ 4ï¼‰ Conv1Dæ¨¡å—ï¼Œ 5ï¼‰è¾“å‡ºå…¨è¿æ¥æ¨¡å—. å¯¹æ¨¡å‹çš„æ·±åº¦å’Œå®½åº¦çš„è€ƒé‡æœ‰ä¸¤ä¸ªä¸»è¦æ–¹é¢ã€‚ ä¸€æ˜¯è®­ç»ƒå’ŒéªŒè¯é›†çš„æ•°é‡æœ‰é™ï¼Œæ ‡æ³¨çš„ç¢±åŸºä¸ªæ•°ä¸€å…±æœ‰ï½1.6Mï¼Œè¿‡å¤§çš„æ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œ äºŒæ˜¯LinearFold/LinearPartitionçš„é¢„æµ‹ç»™äº†å¾ˆå¥½çš„èµ·å§‹ç‚¹ï¼Œ å¯¹æ¨¡å‹ä¼˜åŒ–æœ‰è¾ƒå¥½çš„å¼•å¯¼ã€‚æˆ‘ä»¬æœ€åé‡‡ç”¨çš„å‚æ•°ä¸º, æ¨¡å—1-4çš„å±‚æ•°ä¸º1, ç»´åº¦ä¸º32 ï¼Œè¾“å‡ºå…¨è¿æ¥æ¨¡å—å±‚æ•°ä¸º3, ç»´åº¦åˆ†åˆ«ä¸º32, 32, 2, å½’ä¸€åŒ–ä¸ºLayerNormï¼Œæ¿€æ´»å‡½æ•°ä¸ºReLU, Dropoutä¸º0.2, æœ€ç»ˆå¯è®­ç»ƒçš„å‚æ•°ä¸ªæ•°ä¸º36,418, å¤§çº¦æ˜¯æ ‡æ³¨ä¸ªæ•°çš„2.2%ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/7227509d29654c22ad88326a918926acf836ab482a3045f58bb6fdc64d1245c3" width=480/>

å›¾è¡¨ 4: æ¨¡å‹æ¡†æ¶ç¤ºæ„å›¾

### æ¨¡å‹å®ç° ###

æˆ‘ä»¬ç”¨é£æµ†2.0æ·±åº¦å­¦ä¹ å¹³å°(Paddle)å®ç°æœ¬æ¨¡å‹ï¼Œ è¿‡ç¨‹ä¸­å¤§é‡å‚è€ƒäº†é£æµ†çš„è¯¦ç»†æ–‡æ¡£å’Œå¼€æºçš„æºä»£ç ï¼Œ å°¤å…¶åˆ©ç”¨äº†Paddle.nnä¸­ç›´æ¥å¯ç”¨çš„TransformerEncoder, LSTM, Conv1Dç­‰ç­‰ã€‚æŸå¤±å‡½æ•°ä¹Ÿä¸»è¦é‡‡ç”¨Paddle.nnæä¾›çš„å‡½æ•°åº“ã€‚ä¸ºäº†æ›´ä¾¿æ·çš„æ­å»ºä¸åŒçš„æ¨¡å‹æˆ–æ”¹å˜æ¨¡å‹çš„å‚æ•°ï¼Œæˆ‘ä»¬æŠŠä¸»è¦çš„å‚æ•°å­˜å‚¨åœ¨ä¸€ä¸ªargsç»“æ„é‡Œï¼Œç„¶ååŒ…è£…æ¯ä¸ªæ¨¡å—ï¼ˆæ¯”å¦‚LSTM, Conv1D)èƒ½æ¥å—argsä¸ºè¾“å…¥ï¼Œ å›¾5å±•ç¤ºäº†ç«èµ›æ‰€ç”¨æ¨¡å‹çš„ä»£ç ï¼Œå›¾6å±•ç¤ºäº†å…¶ä¸­ä¸€ä¸ªæ¨¡å—çš„ä»£ç , æ­å»ºè¿‡ç¨‹ç›¸å¯¹ç®€å•, paddle_nets.pyåŒ…å«äº†æ‰€æœ‰æ¨¡å‹å»ºæ„çš„ç›¸å…³ä»£ç .

![](https://ai-studio-static-online.cdn.bcebos.com/851f3bb5c1774cedbddfa4a6e5dd9aec3c091f79f06b451d93af31ed7c66d634)

å›¾è¡¨ 5: ç½‘ç»œæ¡†æ¶æ„å»ºä»£ç èŒƒä¾‹

<img src="https://ai-studio-static-online.cdn.bcebos.com/a83239417f1b4bfa983598977f2385952e20f162246d4e87b1a406501ed4d46b" width=800/>

å›¾è¡¨ 6: æ¨¡å—æ„å»ºä»£ç èŒƒä¾‹

### è¾“å…¥è¾“å‡º ###
å¯¹äºä¸€ä¸ªé•¿åº¦ä¸ºLçš„RNAåºåˆ— æ¯ä¸ªç¢±åŸºå­—ç¬¦ç”¨ä¸€ä¸ªå››ç»´çš„onehotå‘é‡è¡¨è¾¾ï¼Œ LinearFoldçš„äºŒçº§ç»“æ„å­—ç¬¦ç”¨ä¸€ä¸ªå››ç»´çš„onehotå‘é‡è¡¨è¾¾(ä¸‰ç»´è¶³å¤Ÿ,è¿™é‡Œå‡‘äº†ä¸ªå¶æ•°)ï¼ŒLinearPartitioné¢„æµ‹å¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚æœ€ç»ˆå¾—åˆ°çš„è¾“å…¥çŸ©é˜µçš„ç»´åº¦ä¸º [N, L, 10], å…¶ä¸­Næ˜¯batch size, Læ˜¯åºåˆ—é•¿åº¦ã€‚ è¾“å‡ºå…¨è¿æ¥æ¨¡å—çš„æœ€åä¸€å±‚ç»´åº¦åˆ†åˆ«ä¸º2. æ‰€ä»¥æ¨¡å‹çš„è¾“å‡ºæ˜¯ä¸€ä¸ª[N, L, 2]ç»´çš„çŸ©é˜µï¼Œ æ²¿æœ€åä¸€ç»´è¿›è¡Œsoftmaxæ“ä½œï¼Œå¾—åˆ°äº†æ¯ä¸ªç¢±åŸºçš„é…å¯¹å’Œä¸é…å¯¹å‡ ç‡ã€‚æŸå¤±å‡½æ•°æœ‰ä¸¤ç§å¯å–çš„æ–¹æ³•ï¼Œæœ€ç›´æ¥çš„æ˜¯å¯¹ä¸é…å¯¹å‡ ç‡è®¡ç®—ç«èµ›é‡‡ç”¨çš„å‡å¹³æ–¹å·®çš„å¹³æ–¹æ ¹ï¼ˆRMSEï¼‰ï¼Œ åŒæ—¶è€ƒè™‘ç»“æœä¸ºsoftmaxåçš„å‡ ç‡ï¼Œæ ‡æ³¨ä¸ºäºŒåˆ†ç±»çš„è½¯æ ‡æ³¨ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é‡‡ç”¨äº¤å‰ç†µåšä¸ºæŸå¤±ã€‚ ä¸¤ç§ä¸åŒä¸»è¦åœ¨äºäº¤å‰ç†µåœ¨å¯¹å‡ ç‡pçš„æ¢¯åº¦ä¸Šå¤šäº†ä¸€ä¸ª1/p(1-p)çš„å› å­ï¼Œå¯¹æ¥è¿‘0æˆ–1çš„å‡ ç‡æ¢¯åº¦å¢å¼ºã€‚ åœ¨å®éªŒä¸­æˆ‘ä»¬å‘ç°ä¸¤ç§æŸå¤±å‡½æ•°çš„ç»“æœæ˜¯å¤§ä½“ç›¸åŒï¼Œ çŒœæƒ³æ˜¯å› ä¸ºå‡ ç‡ä¸»è¦åˆ†å¸ƒåœ¨0å’Œ1çš„é™„è¿‘ï¼Œ è¿™ä¸ªé™„åŠ å› å­çš„ä½œç”¨ä¸æ˜¾è‘—. 

### æ¨¡å‹è®­ç»ƒ ###
æ¨¡å‹è®­ç»ƒåœ¨å•ä¸ªCPUä¸Šè¿›è¡Œ, æ¯ä¸ªepochå¤§çº¦5åˆ†é’Ÿï¼Œä¸€èˆ¬ä¸€ä¸¤ä¸ªå°æ—¶èƒ½è®­ç»ƒç»“æŸ. æœ‰å…³ä»£ç åœ¨fly_paddle.pyè„šæœ¬é‡Œ. å‰æ–‡æåˆ°çš„argsåŒ…å«äº†å¤§éƒ¨åˆ†æ¨¡å‹å’Œè®­ç»ƒçš„å‚æ•°, fly_paddle.pyè®¾ç½®äº†ç¼ºçœå‚æ•°,  åŒæ—¶å¯ä»¥åœ¨å‘½ä»¤è¡Œè®¾ç½®å‚æ•°å–å€¼, å›¾7æ¼”ç¤ºäº†å‘½ä»¤è¡Œå¯åŠ¨æ¨¡å‹è®­ç»ƒçš„ç•Œé¢, è®­ç»ƒæ—¶æ±‡æŠ¥æŸå¤±ç•Œé¢å¦‚å›¾8æ‰€ç¤º.

![](https://ai-studio-static-online.cdn.bcebos.com/8ff0490f54d740148e120f2577e9c39afb3ea482d8da4c82b809ef55f7b313fc)

å›¾è¡¨ 7: å‘½ä»¤è¡Œå¯åŠ¨æ¨¡å‹è®­ç»ƒèŒƒä¾‹

![](https://ai-studio-static-online.cdn.bcebos.com/0c176a62798c4b80ba4ff86926f297f6ef045abb0a684e48bc0926dca4967f51)

å›¾è¡¨ 8: æ¨¡å‹è®­ç»ƒä¸­çš„è¿›åº¦æ±‡æŠ¥èŒƒä¾‹

æ¨¡å‹çš„è®­ç»ƒä¸»è¦åˆ†ä»¥ä¸‹ä¸‰æ­¥éª¤:
ç¬¬ä¸€æ­¥æ˜¯å¯¹æ·±åº¦å­¦ä¹ ä»»åŠ¡åŸ¹å…»ä¸€äº›ç›´è§‰ã€‚æˆ‘ä»¬å…ˆç”¨æœ€ç®€å•çš„å…¨è¿æ¥æ¨¡å‹çœ‹ä¸€ä¸‹åœ¨ä¸è€ƒè™‘ç¢±åŸºé—´ç›¸äº’ä½œç”¨æƒ…å†µä¸‹çš„RMSEã€‚å¦‚æœè¾“å…¥çš„ç¢±åŸºä¿¡æ¯åªæœ‰å…¶å­—ç¬¦ç¼–ç çš„å››ç»´çš„onehotå‘é‡ï¼Œ RMSEä¸ºï½0.42ï¼Œä¸å‡ºæ‰€æ–™å’ŒéšæœºçŒœæµ‹å‡ ç‡ç›¸å·®æ— å‡ ï¼ŒåŠ å…¥LinearFoldå’ŒLinearPartitioné¢„æµ‹ä¿¡æ¯èƒ½é™ä½RMSEåˆ°0.25å·¦å³ã€‚å¯è§LinearFoldå’ŒLinearPartitionç»™å‡ºäº†å¾ˆå¥½çš„åˆå§‹ç‚¹ï¼Œå¦‚æœè¦è¿›ä¸€æ­¥é™ä½RMSE, æˆ‘ä»¬éœ€è¦è€ƒè™‘ç¢±åŸºä¹‹é—´çš„ç›¸äº’ä½œç”¨.

ç¬¬äºŒæ­¥æ˜¯åˆ†æ­¥åŠ å…¥TransformerEncoder, LSTMå’ŒConv1Dæ¨¡. æˆ‘ä»¬å‘ç°å•ä¸€çš„TransformerEncoderæˆ–è€…LSTMè¶³å¤Ÿé™ä½RMSEåˆ°0.21-0.22ä¹‹é—´ï¼ŒConv1Dæ¨¡å—å¯¹RMSEå½±å“è¾ƒå°, è¿™ä¸æˆ‘ä»¬çš„æœŸæœ›ä¹Ÿå¤§è‡´ç›¸ç¬¦ï¼Œå› ä¸ºä¸€å±‚çš„Conv1Dä¹Ÿåªæ˜¯è€ƒè™‘åˆ°äº†ç´§é‚»ç¢±åŸºä¹‹é—´çš„ä½œç”¨ã€‚æœ€åä¸‰ä¸ªæ¨¡å—ä¸€èµ·èƒ½é™ä½RMSEåˆ°0.20-0.21åŒºé—´ã€‚

ç¬¬ä¸‰æ­¥ä¸»è¦æ˜¯æ‘¸ç´¢è¶…å‚æ•°å’Œæ”¹è¿›æ¨¡å‹æ¥è¿›ä¸€æ­¥é™ä½RMSEã€‚æˆ‘ä»¬é¦–å…ˆå¯¹learning_rateï¼Œ dropout, å’Œweight decayåšäº†ä¸€ç³»åˆ—çš„æ‘¸ç´¢ï¼Œ å‘ç°åœ¨å¸¸ç”¨çš„è¶…å‚æ•°åŒºé—´é‡Œæ¨¡å‹è¡¨ç°ç›¸å½“ï¼Œ åŸå› å¯èƒ½ä¸»è¦æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯å‚æ•°ç©ºé—´ç›¸å¯¹è¾ƒå°ï¼Œå…¶äºŒæ˜¯èµ·å§‹çš„æ•°æ®å’Œæ ‡æ³¨ç›¸è·ä¸è¿œ. å› ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„RMSEåœ¨æ‰€æœ‰çš„è®­ç»ƒä¸­RMSEç›¸å½“, æˆ‘ä»¬æ²¡æœ‰é‡‡ç”¨å‚æ•°æ­£åˆ™åŒ–.  

æˆ‘ä»¬å¯¹æ”¹è¿›æ¨¡å‹çš„åŠªåŠ›æ”¶è·è¾ƒå°ã€‚å›¾9å±•ç¤ºäº†å¯¹è®­ç»ƒé›†åºåˆ—ä¸­æ¨¡å‹é¢„æµ‹çš„ç¢±åŸºä¸é…å¯¹å‡ ç‡åˆ†å¸ƒï¼Œ æœ€çªå‡ºçš„é—®é¢˜æ˜¯æœ‰39%çš„ç¢±åŸºçš„å‡ ç‡åœ¨[0.1, 0.9]åŒºé—´å†…ï¼Œè€Œæ ‡æ³¨é›†ä¸­åªæœ‰22%ç¢±åŸºçš„çš„ä¸é…å¯¹å‡ ç‡åœ¨æ­¤åŒºé—´ã€‚ä¸€ä¸ªæ¯”è¾ƒç®€å•ç›´æ¥çš„æ–¹æ³•æ˜¯å¢åŠ [0.1, 0.9]åŒºé—´å¯¹æŸå¤±çš„è´¡çŒ®ï¼Œæ¯”å¦‚ä»æŸå¤±ä¸­å‡å»(å‡ ç‡-0.5)çš„å¹³æ–¹, å¯æ˜¯è¿™æ–¹é¢çš„å°è¯•å¹¶æ²¡æœ‰å‡å°RMSEã€‚æˆ‘ä»¬é‡‡ç”¨çš„äº¤å‰ç†µèƒ½å¢åŠ åœ¨0/1é™„è¿‘çš„æ¢¯åº¦ï¼Œä¹Ÿæ²¡æœ‰èƒ½å¤Ÿå‡å°RMSEã€‚å¦å¤–ä¸€ä¸ªæ˜æ˜¾çš„é—®é¢˜æ˜¯RMSEè¿‡å¤§ï¼Œå¸¸è§çš„è§£å†³æ–¹æ³•æ˜¯å¢åŠ æ¨¡å‹çš„æ·±åº¦æˆ–å®½åº¦ï¼Œæˆ‘ä»¬å‘ç°æ›´å¤§çš„æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼ˆæ¯”å¦‚æ¨¡å—ç»´åº¦ä¸º128å±‚æ•°ä¸º3æ—¶å¯è¾¾åˆ°RMSE < 0.1ï¼‰ï¼Œå¯éªŒè¯æ•°æ®çš„RMSEåœç•™åœ¨0.2å·¦å³ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„è¿‡åº¦æ‹Ÿåˆç°è±¡ï¼Œæ‰€ä»¥æ²¡æœ‰é‡‡ç”¨æ›´å¤§çš„æ¨¡å‹ã€‚

<img src="https://ai-studio-static-online.cdn.bcebos.com/15636ffe2dc347328d46774059f356233c842e16bb5447bc86939158b46882ed" width=600/>

å›¾è¡¨ 9: æ¨¡å‹é¢„æµ‹ç¢±åŸºä¸é…å¯¹å‡ ç‡åˆ†å¸ƒ

åœ¨æœ€åé€’äº¤çš„é¢„æµ‹ç»“æœé‡Œ, é‰´äºæˆ‘ä»¬çš„æ¨¡å‹è¾ƒå°, æˆ‘ä»¬é‡‡ç”¨äº†æ¨¡å‹å¹³å‡ã€‚åœ¨æ¯æ¬¡è®­ç»ƒä¸­æˆ‘ä»¬ä»è®­ç»ƒé›†ä¸­éšæœºé€‰å–10%çš„åºåˆ—åšä¸ºéªŒè¯é›†å¹¶å­˜å–éªŒè¯é›†æœ€å°RMSEçš„æ¨¡å‹å‚æ•°ã€‚å¤šæ¬¡çš„è®­ç»ƒå°±å¾—åˆ°ä¸åŒçš„å‚æ•°é›†çš„åŒä¸€æ¨¡å‹ï¼Œæœ€åçš„ç»“æœæˆ‘ä»¬å¹³å‡äº†ä¸‰ä¸ªæœ€å¥½çš„å‚æ•°é›†çš„é¢„æµ‹ã€‚å¯èƒ½å› ä¸ºæ˜¯å‡ºäºåŒä¸€æ¨¡å‹ï¼Œæ¨¡å‹å¹³å‡ä¹Ÿä»…é™ä½RMSEä¸åˆ°0.5%ã€‚

## æ€»ç»“ä¸è®¨è®º ##
æœ¬æ–‡ä¸»è¦å™è¿°äº†ä½œè€…å‚åŠ èºæ—‹æ¡¨RNAç»“æ„é¢„æµ‹ç«èµ›çš„è¿‡ç¨‹, å°¤å…¶å…³äºæ¢ç´¢çš„å¾ˆå¤šèµ°çš„é€šå’Œèµ°ä¸é€šçš„æ–¹å‘, å¸Œæœ›å¯¹æ„Ÿå…´è¶£çš„è¯»è€…æœ‰äº›å€Ÿé‰´. åŸºå› ç–—æ³•å›¢é˜Ÿæ˜¯æ·±åº¦å­¦ä¹ çš„åˆå­¦è€…, ä¸€ä¸ªå¾ˆå¤§çš„æ„Ÿè§¦æ˜¯é£æµ†æ·±åº¦å­¦ä¹ å¹³å°çš„å¼ºå¤§åŠŸèƒ½å’Œæä½çš„å­¦ä¹ é—¨æ§›ã€‚æˆ‘ä»¬æ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ­å»ºç»å¤§éƒ¨åˆ†ç”¨çš„æ˜¯é£æµ†å¹³å°æä¾›çš„æˆç†Ÿçš„åº“å‡½æ•°ï¼ŒåŒ…æ‹¬ç”¨åˆ°çš„TransformerEncoder /LSTMç­‰ç­‰åªéœ€ç›´æ¥è°ƒç”¨ã€‚é£æµ†æ˜¯æˆ‘ä»¬å­¦ä¹ çš„ç¬¬ä¸€ä¹Ÿæ˜¯å”¯ä¸€çš„æ·±åº¦å­¦ä¹ å¹³å°, è¿™äº›ä½è¯äº†é£æµ†çš„æˆç†Ÿå’Œæ˜“ç”¨æ€§ã€‚ 

å¦‚å‰æ–‡æ‰€è¿°, RNAç¢±åŸºä¸é…å¯¹å‡ ç‡å¯¹ç§‘å­¦å’ŒåŒ»å­¦æ„ä¹‰é‡å¤§, å°¤å…¶æˆ‘ä»¬å¯ä»¥è¯´RNAåŒ»å­¦å·²ç»åˆ°æ¥è€Œä¸”å¿…å°†è“¬å‹ƒå‘å±•. è¿™æ¬¡ç«èµ›ä¹Ÿæ­£æ˜¯ä¸ºäº†æé«˜å¯¹ç¢±åŸºä¸é…å¯¹å‡ ç‡é¢„æµ‹çš„ç²¾åº¦, æˆ‘ä»¬åœ¨è®­ç»ƒä¸­èƒ½è¾¾åˆ°å’ŒéªŒè¯é›†çš„RMSE~0.20, æ¯”èµ›æµ‹è¯•é›†å¾—åˆ°çš„RMSEå·®ä¸€äº›, ~0.24. æˆ‘ä»¬çŒœæƒ³ä¸€ä¸ªåŸå› æ˜¯æµ‹è¯•é›†æœ‰31%çš„åºåˆ—é•¿åº¦è¶…è¿‡è®­ç»ƒå’ŒéªŒè¯é›†ä¸­çš„æœ€é•¿åºåˆ—é•¿åº¦, å¢åŠ äº†é¢„æµ‹éš¾åº¦. æ— è®ºæ˜¯0.20è¿˜æ˜¯0.24, å’Œå®éªŒç»“æœéƒ½ç›¸è·ç”šè¿œ, è¿˜è¿œè¿œè¾¾ä¸åˆ°å®ç”¨æˆ–å’Œå®éªŒåª²ç¾çš„ç²¾åº¦, å¯æé«˜çš„ç©ºé—´è¿˜å¾ˆå¤š. åœ¨ç°æœ‰çš„åŸºç¡€ä¸Šæˆ‘ä»¬è¿˜å¯ä»¥å°è¯•æ›´å¤šçš„æ–¹æ³•æ¥æé«˜é¢„æµ‹ç²¾åº¦, ä¸‹é¢è®¨è®ºä¸€äº›å¯èƒ½çš„æ–¹å‘.

é¦–å…ˆ, æˆ‘ä»¬å¯ä»¥å¢å¼ºè¾“å…¥ä¿¡æ¯. æ¯”å¦‚åœ¨LinearFoldå’ŒLinearPartitionçš„åŸºç¡€ä¸Šæˆ‘ä»¬å¯ä»¥åŠ å…¥æ›´å¤šè®¡ç®—æ–¹æ³•çš„é¢„æµ‹æ•°æ®. åœ¨RNAç»“æ„é¢„æµ‹é¢†åŸŸæœ‰å¾ˆå¤šå¯ç”¨çš„è½¯ä»¶, æ¯”å¦‚åŸºäºç‰©ç†çš„MFOLD[4], VIENNA RNAFOLD[5], RNASTRUCTURE[6], åŸºäºæœºå™¨å­¦ä¹ çš„CONTRAFOLD[7], CDPFOLD[8], å’Œè¿‘å¹´æ¥å¿«é€Ÿå‘å±•çš„æ·±åº¦å­¦ä¹ æ–¹æ³•SPOT-RNA[9], E2EFOLD[10], MXFOLD2[11], DIRECT[12], RNACONCAT[13], DMFOLD[14]. 

å…¶æ¬¡, æˆ‘ä»¬çš„æ¨¡å‹ç›¸å¯¹è¾ƒå°, éš¾äºæ•æ‰RNAç¢±åŸºé…å¯¹æ‰€å—æ”¯é…çš„ç¢±åŸºé—´çš„å¤šä½“ç›¸äº’å¸å¼•ä¸ç«äº‰, æ‰€ä»¥ä¸€ä¸ªæé«˜é¢„æµ‹ç²¾åº¦çš„æ–¹å‘æ˜¯è®­ç»ƒæ›´å¤§çš„æ¨¡å‹. å°¤å…¶æ˜¯å½“RNAåºåˆ—é•¿åº¦æ›´é•¿, æ¯”å¦‚æ–°å† ç—…æ¯’çš„åŸºå› æœ‰~30,000ä¸ªç¢±åŸº, mRNAç–«è‹—ä¹Ÿæœ‰å‡ åƒä¸ªç¢±åŸº, å¹¶ä¸”å…¶ç¢±åŸºç»è¿‡å¤§é‡çš„åŒ–å­¦ä¿®é¥°, é¢„æµ‹å…¶ç»“æ„æ›´æ˜¯éš¾ä¸ŠåŠ éš¾. è¦èƒ½å¤Ÿé¢„æµ‹æ›´é•¿æ›´å¤æ‚çš„RNA, æ›´å¤§çš„æ¨¡å‹å‡ ä¹æ˜¯å¿…é¡»çš„. æ¯”å¦‚å›¾10å±•ç¤ºäº†æ¨¡å‹å’Œæ ‡æ³¨ä¹‹é—´çš„å¯¹æ¯”, ä¸Šä¸‹ä¸¤ç»„çš„é•¿åº¦åˆ†åˆ«ä¸º110å’Œ480, æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¯¹è¾ƒçŸ­çš„åºåˆ—é¢„æµ‹å‡†ç¡®åº¦å¾ˆé«˜, å¯æ˜¯å¯¹é•¿åºåˆ—çš„é¢„æµ‹å·®è·å¾ˆå¤§. æ›´å¤§çš„æ¨¡å‹å°±éœ€è¦æ›´å¤šçš„æ›´å…¨é¢çš„è®­ç»ƒæ•°æ®, å°¤å…¶å¯¹äºæœ‰åŒ–å­¦ä¿®é¥°çš„ç¢±åŸº, å®éªŒæµ‹é‡å¾ˆæœ‰å¯èƒ½æ˜¯ä¸€ä¸ªç“¶é¢ˆ. éœ€è¦æˆ‘ä»¬å¦è¾Ÿè¹Šå¾„, æ¯”å¦‚ç”¨æ¨¡æ‹Ÿçš„æ–¹æ³•å¾—åˆ°æ›´å¤šçš„æ•°æ®. 

![](https://ai-studio-static-online.cdn.bcebos.com/a35b6dd3835f4c8fa35a3f277a6a9b279f721edf220a4fb694723144f3d2d8e3)
![](https://ai-studio-static-online.cdn.bcebos.com/cdc9f78781f64feb8e838fe9a2b2f1ebbf61c233d67d46c58f7e8524459c5d56)

å›¾è¡¨ 10: æ¨¡å‹é¢„æµ‹ç¢±åŸºä¸é…å¯¹å‡ ç‡å’Œæ ‡æ³¨çš„å¯¹æ¯”, ä¸Šæ’ä¸¤å›¾ä¸­çš„RNAèŒƒä¾‹é•¿åº¦ä¸º110, ä¸‹æ’é•¿åº¦ä¸º480. å·¦åˆ—ä¸¤å›¾å±•ç¤ºäº†æ ‡æ³¨(è“),é¢„æµ‹(çº¢)å’Œå®ƒä»¬çš„å·®(ç»¿)å¯¹åºåˆ—ä½ç½®(X), å³åˆ—ä¸¤å›¾å±•ç¤ºäº†é¢„æµ‹(Y)å¯¹æ ‡æ³¨(X).

æœ€å, ä»çº¯ç§‘å­¦è§’åº¦ä¸Š, ä¸€ä¸ªç†æƒ³çš„æ¨¡å‹åªéœ€è¦RNAåºåˆ—ä¿¡æ¯çš„å°±èƒ½å‡†ç¡®é¢„æµ‹ç¢±åŸºä¸é…å¯¹å‡ ç‡å’Œå…¶å®ƒçš„ç»“æ„ä¿¡æ¯. è¿™å¹¶ä¸æ˜¯å¯æœ›è€Œä¸å¯åŠçš„, åœ¨ç°æœ‰çš„æ–¹æ³•é‡Œ, æ¯”å¦‚ç™¾åº¦èºæ—‹æ¡¨çš„LinearFold/LinearPartitionå’Œå‰é¢æåˆ°çš„ç¬¬ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ–¹æ³•SPOT-RNAéƒ½åªéœ€è¦åºåˆ—å°±å¯ä»¥éå¸¸å¥½çš„é¢„æµ‹RNAçš„äºŒçº§ç»“æ„. å½“ç„¶ä»å®ç”¨è§’åº¦ä¸Šçœ‹, å³ä½¿ä¸€ä¸ªæ–¹æ³•éœ€è¦ç»¼åˆå¾ˆå¤šæ–¹é¢çš„ä¿¡æ¯(æ¯”å¦‚éœ€è¦èšåˆå¾ˆå¤šç°æœ‰è½¯ä»¶çš„é¢„æµ‹ç»“æœ), å¦‚æœèƒ½è¾ƒå¿«çš„å‡†ç¡®é¢„æµ‹RNAç»“æ„, é‚£ä¹Ÿå·²è¶³å¤Ÿ. æ¡æ¡å¤§è·¯é€šç½—é©¬, å¾ˆå¤šé“è·¯éœ€è¦æ‘¸ç´¢, æ¯æ¡è·¯éƒ½éœ€è¦å¾ˆå¤šäººçš„ä¸æ‡ˆåŠªåŠ›.

### å¼•ç”¨æ–‡çŒ® ###
1.	Huang L, Zhang H, Deng D, Zhao K, Liu K, Hendrix DA, Mathews DH. LinearFold: linear-time approximate RNA folding by 5'-to-3' dynamic programming and beam search. Bioinformatics. 2019;35(14):i295-i304. 
2.	Zhang H, Zhang L, Mathews DH, Huang L. LinearPartition: linear-time approximation of RNA folding partition function and base-pairing probabilities. Bioinformatics. 2020;36(Supplement_1):i258-i67. 
3.	Zhang H, Zhang L, Li Z, Liu K, Liu B, Mathews DH, Huang L. LinearDesign: Efficient Algorithms for Optimized mRNA Sequence Design2020 April 01, 2020:[arXiv:2004.10177 p.]. Available from: https://ui.adsabs.harvard.edu/abs/2020arXiv200410177Z.
4.	Zuker M. Mfold web server for nucleic acid folding and hybridization prediction. Nucleic Acids Research. 2003;31(13):3406-15. 
5.	Lorenz R, Bernhart SH, HÃ¶ner zu Siederdissen C, Tafer H, Flamm C, Stadler PF, Hofacker IL. ViennaRNA Package 2.0. Algorithms for Molecular Biology. 2011;6(1):26. 
6.	Reuter JS, Mathews DH. RNAstructure: software for RNA secondary structure prediction and analysis. BMC Bioinformatics. 2010;11(1):129. 
7.	Do CB, Woods DA, Batzoglou S. CONTRAfold: RNA secondary structure prediction without physics-based models. Bioinformatics. 2006;22(14):e90-e8. 
8.	Zhang H, Zhang C, Li Z, Li C, Wei X, Zhang B, Liu Y. A New Method of RNA Secondary Structure Prediction Based on Convolutional Neural Network and Dynamic Programming. Frontiers in Genetics. 2019;10(467). 
9.	Singh J, Hanson J, Paliwal K, Zhou Y. RNA secondary structure prediction using an ensemble of two-dimensional deep neural networks and transfer learning. Nature Communications. 2019;10(1):5407. 
10.	Chen X, Li Y, Umarov R, Gao X, Song L. RNA Secondary Structure Prediction By Learning Unrolled Algorithms2020 February 01, 2020:[arXiv:2002.05810 p.]. Available from: https://ui.adsabs.harvard.edu/abs/2020arXiv200205810C.
11.	Sato K, Akiyama M, Sakakibara Y. RNA secondary structure prediction using deep learning with thermodynamic integration. Nature Communications. 2021;12(1):941. 
12.	Jian Y, Wang X, Qiu J, Wang H, Liu Z, Zhao Y, Zeng C. DIRECT: RNA contact predictions by integrating structural patterns. BMC Bioinformatics. 2019;20(1):497. 
13.	Sun S, Wang W, Peng Z, Yang J. RNA inter-nucleotide 3D closeness prediction by deep residual neural networks. Bioinformatics. 2020;37(8):1093-8. 
14.	Wang L, Liu Y, Zhong X, Liu H, Lu C, Li C, Zhang H. DMfold: A Novel Method to Predict RNA Secondary Structure With Pseudoknots Based on Deep Learning and Improved Base Pair Maximization Principle. Frontiers in Genetics. 2019;10(143). 


## é™„
### ä½¿ç”¨æ–¹å¼

è¯¦ç»†ä½¿ç”¨æ–¹æ³•è¯·å‚ç…§fly.ipynbä¸­çš„æ–‡æ¡£å†…å®¹.

Aï¼šåœ¨AI Studioä¸Š[è¿è¡Œæœ¬é¡¹ç›®](https://aistudio.baidu.com/aistudio/projectdetail/1479469)

     éœ€è¦æ‹·è´workç›®å½•å’Œfly.ipynb ä¿æŒåŸæœ‰ç›®å½•ç»“æ„ï¼Œå³å¯è¿è¡Œfly.ipynb

Bï¼šåœ¨æœ¬æœºè¿è¡Œæ–¹æ³•å¦‚ä¸‹ï¼š

    1) å…‹éš† github repo åˆ°æœ¬åœ°ç›®å½•

    2) å®‰è£…æ‰€éœ€å‡½æ•°åº“ (å‚ç…§requirements.txt)
    
    3) è¿è¡Œ fly.ipynb

### è¿è¡Œç¤ºèŒƒ

```python
# å¦‚æœéœ€è¦è¿›è¡ŒæŒä¹…åŒ–å®‰è£…, éœ€è¦ä½¿ç”¨æŒä¹…åŒ–è·¯å¾„, å¦‚ä¸‹æ–¹ä»£ç ç¤ºä¾‹:
# If a persistence installation is required, 
# you need to use the persistence path as the following: 
# !mkdir /home/aistudio/external-libraries
# !pip install colorlog -t /home/aistudio/external-libraries
```


```python
# ç¨‹åºåœ¨/work/codeç›®å½•ä¸‹ï¼Œ éœ€å…ˆåŠ å…¥è·¯å¾„
import sys 
sys.path.append('/home/aistudio/work/code')
sys.path.append('/home/aistudio/external-libraries')
# fly_paddleæ˜¯å”¯ä¸€éœ€è¦ç›´æ¥è°ƒç”¨çš„æ¨¡å—
# fly_paddle is the only module required for interactive sessions
import fly_paddle as fp

# argsåŒ…æ‹¬å‡ ä¹æ‰€æœ‰éœ€è¦çš„å‚æ•°ï¼Œ è´¯ç©¿äºå‡ ä¹æ‰€æœ‰çš„ç¨‹åºè°ƒç”¨ä¸­
# argsç”±fp.parse_args2()æ ¹æ®ä»»åŠ¡åˆå§‹åŒ–, è¦ç”¨åˆ°çš„ä»»åŠ¡åŒ…æ‹¬ï¼š â€˜train', 'validate', 'predict'
# args is a structure storing most (if not all) parameters and used for most function calls.
# args is initialized by fp.parse_args2(), depending on the specific task, such as "train", "validate" "predict"
args, _ = fp.parse_args2('train')
print(fp.gwio.json_str(vars(args)))
# æ³¨ï¼š æ ¹æ®ä¸åŒçš„ç½‘ç»œç­‰ç­‰éœ€è¦ï¼Œ argså¯èƒ½åŒ…å«ä¸€äº›ç”¨ä¸åˆ°çš„å‚æ•°
# Attention: some parameters in args may not be used depending on the network etc.
```

    {
       "action": "train",
       "argv": "-h",
       "verbose": 1,
       "resume": false,
       "load_dir": null,
       "save_dir": null,
       "save_level": 2,
       "save_grpby": ["epoch", "batch"],
       "log": "fly_paddle-Jun19.log",
       "data_args": "======= data args =======",
       "data_dir": "data",
       "data_name": "predict",
       "data_suffix": ".pkl",
       "data_size": 0,
       "test_size": 0.1,
       "split_seed": null,
       "input_genre": "Seq",
       "input_fmt": "NLC",
       "seq_length": [0, 512, -1],
       "residue_fmt": "vector",
       "residue_nn": 0,
       "residue_dbn": false,
       "residue_attr": false,
       "residue_extra": false,
       "label_genre": "upp",
       "label_fmt": "NL",
       "label_tone": "none",
       "label_ntype": 2,
       "label_smooth": false,
       "net_args": "======= net args =======",
       "net_src_file": "/home/aistudio/work/code/paddle_nets.py",
       "net": "lazylinear",
       "resnet": false,
       "act_fn": "relu",
       "norm_fn": "none",
       "norm_axis": -1,
       "dropout": 0.2,
       "feature_dim": 1,
       "embed_dim": 32,
       "embed_num": 1,
       "linear_num": 2,
       "linear_dim": [32],
       "linear_resnet": false,
       "conv1d_num": 1,
       "conv1d_dim": [32],
       "conv1d_resnet": false,
       "conv1d_stride": 1,
       "conv2d_num": 1,
       "conv2d_dim": [32],
       "conv2d_resnet": false,
       "attn_num": 2,
       "attn_nhead": 2,
       "attn_act": "relu",
       "attn_dropout": null,
       "attn_ffdim": 32,
       "attn_ffdropout": null,
       "lstm_num": 2,
       "lstm_dim": [32],
       "lstm_direct": 2,
       "lstm_resnet": false,
       "output_num": 1,
       "output_dim": [32, 32, 2],
       "output_resnet": false,
       "optim_args": "======= optim args =======",
       "optim": "adam",
       "learning_rate": 0.003,
       "beta1": 0.9,
       "beta2": 0.999,
       "epsilon": 1e-08,
       "lr_scheduler": "reduced",
       "lr_factor": 0.9,
       "lr_patience": 10,
       "weight_decay": "none",
       "l1decay": 0.0001,
       "l2decay": 0.0001,
       "train_args": "======= train/loss args =======",
       "batch_size": 4,
       "num_epochs": 777,
       "num_recaps_per_epoch": 30,
       "num_callbacks_per_epoch": 10,
       "loss_fn": ["mse"],
       "loss_fn_scale": [1],
       "loss_sqrt": false,
       "loss_padding": false,
       "validate_callback": null,
       "trainloss_rdiff": 0.001,
       "validloss_rdiff": 0.001,
       "trainloss_patience": 11,
       "validloss_patience": 11,
       "mood_args": "======= mood args =======",
       "debug": false,
       "lucky": false,
       "lazy": false,
       "sharp": false,
       "comfort": false,
       "explore": false,
       "exploit": false,
       "diehard": false,
       "tune": false,
       "action_args": "======= action args ======="
    }


    /home/aistudio/work/code/misc.py:52: DeprecationWarning: invalid escape sequence \e
      """ escape char: \033 \e \x1B  """



```python
# ä¸¤ç§æ›´æ–°argsçš„æ–¹æ³•ï¼š 1ï¼‰ args.update(**dict), 2) args.[key] = value
# Two main ways to update values in args: 1) args.update(**dict), 2) args.[key] = value
args.update(data_dir='work/data', data_name='train', residue_dbn=True, residue_extra=True)

# ç½‘ç»œå‚æ•° ï¼ˆnet parameters): 
# ç½‘ç»œçš„è®¾è®¡ä¸»è¦è€ƒè™‘äº†ä¸‰ä¸ªæ”¯é…RNAç¢±åŸºé…å¯¹çš„å› ç´ ï¼š 
#    1) æ¥è‡ªäºå…¨éƒ¨åºåˆ—çš„æ’åˆ—ç»„åˆï¼ˆé…åˆ†ï¼‰ç«äº‰ï¼Œç”¨Attentionæœºåˆ¶æ¥æ¨¡æ‹Ÿ
#    2ï¼‰æ¥è‡ªäºçº¿æ€§å¤§åˆ†å­çš„ä¸€ç»´åºåˆ—é™åˆ¶ï¼Œ ç”¨LSTMç»“æ„æ¥æ¨¡æ‹Ÿ
#    3ï¼‰æ¥è‡ªäºå±€éƒ¨ç´§é‚»ç¢±åŸºçš„åˆä½œï¼ˆæ¯”å¦‚ï¼Œä¸€ä¸ªå­¤ç«‹çš„ç¢±åŸºå¯¹æä¸ç¨³å®šï¼‰ï¼Œ ç”¨1D Convolutionæ¥æ¨¡æ‹Ÿ
# æ‰€ä»¥æ¡†æ¶ç”±ä»¥ä¸Šä¸‰ä¸ªæ¨¡å—ç»„æˆï¼Œ å¹¶åœ¨è¾“å…¥å’Œè¾“å‡ºå±‚åŠ äº†1-3ä¸ªçº¿æ€§å±‚ã€‚é™¤éç‰¹æ„è¯´æ˜ï¼Œ æ‰€æœ‰çš„éšè—å±‚çš„ç»´åº¦ä¸º32.
# è®­ç»ƒä¸­å‘ç°é«˜ç»´åº¦å’Œæ·±åº¦çš„ç½‘ç»œå¹¶ä¸èƒ½ç»™å‡ºæ›´å¥½çš„ç»“æœï¼
# Three main mechanisms directing RNA base pairing are taken into consideration for the 
# design of the network architecture. 
#   1) The combinatorial configurational space of attainable RNA base pairs, approximated by Attention Mechanism
#   2) The quasi-1D nature of unbranched, continuous RNA polymers, approximated by LSTM
#   3) The cooperativity of neighboring bases for stable base pairing, approximated by 1D Convolution
# Hence the neural net comprises of three main building blocks, in addition to linear layers for the input and output. 
# The dimensions of all hidden layers are 32 unless noted otherwise.
# Wider and/or deeper nets gave similar, but no better, performances!
args.net='seq2seq_attnlstmconv1d'  # the net name defined in paddle_nets.py
# è¾“å…¥æ¨¡å—ç”±ä¸€ä¸ªçº¿æ€§å±‚ç»„æˆ
# The input block is a single linear feedforward layer
args.linear_num = 1 # the number of linear feedforward layers
# ä¸‰å¤§å¤„ç†æ¨¡å— (the three main data-crunching blocks)
args.attn_num = 1 # the number of transformer encoder layers
args.attn_nhead = 2 # the number of heads (2 chosen to capture paired/unpaired states, naively)
args.lstm_num = 1 # the number of bidirectional lstm layers
args.conv1d_num = 1 # the number of 1D convolution layers
# è¾“å‡ºæ¨¡å—ç”±ä¸‰ä¸ªçº¿æ€§å±‚ç»„æˆï¼Œ ç»´åº¦åˆ†åˆ«ä¸º32, 32, 2
# Three linear layers for the final output, with dimensions of 32, 32, and 2, respectively
args.output_dim = [32, 32, 2]
# å¦‚æœåºåˆ—è¢«è¡¥é•¿åˆ°åŒä¸€é•¿åº¦ï¼Œ å¯¹å½’ä¸€åŒ–çš„å½±å“ä¸æ¸…æ¥šï¼Œ æ‰€ä»¥ç”¨batch_size=1
# If sequences are padded to the same length, such padding may interfere with normalization, hence batch_size=1 
args.norm_fn = 'layer' # layer normalization
args.batch_size = 1 # 1 is used in consideration of the layer norm above
# æœ€åé€’äº¤ç”¨çš„æŸå¤±å‡½æ•°é€‰ä¸ºsoftmax+bce, ä¹Ÿå¯ä»¥ç”¨ softmax+mse, ç»“æœå‡ ä¹ä¸€æ ·
# The submitted results were trained with softmax+bce as the loss function. 
# Essentially the same results were obtained with softmax+mse
args.loss_fn = ['softmax+bce'] # softmax is needed here as the final output has a dimension of 2
args.label_tone = 'soft' # soft label for upp
args.loss_sqrt = True # sqrt(loss) is only necessary for softmax+mse
args.loss_padding = False # exclude padded residues from loss calculation
# éœ€è¦è¿è¡Œfp.autoconfig_args()æ¥æ¶ˆé™¤å‚æ•°çš„ä¸ä¸€è‡´æ€§
# fp.autoconfig_args() needs to be run to resolve inconsistencies between parameters
args = fp.autoconfig_args(args)
```


```python
# å»ºç«‹å’Œæ£€æµ‹æ¨¡å‹ ï¼ˆGet and inspect the modelï¼‰
model = fp.get_model(args)
# æ³¨ï¼š æœ€åçš„è¾“å‡ºçŸ©é˜µçš„ç»´åº¦ä¸º[N, L, 2]
# Note: the shape of the output is [N, L, 2]
```

    2021-06-19 18:48:33,958 - INFO - Used net definition: [0;39;46m/home/aistudio/work/code/paddle_nets.py[0m
    2021-06-19 18:48:34,041 - INFO - {'total_params': 36418, 'trainable_params': 36418}
    2021-06-19 18:48:34,042 - INFO - Optimizer method: adam
    2021-06-19 18:48:34,042 - INFO -    learning rate: 0.003
    2021-06-19 18:48:34,043 - INFO -     lr_scheduler: reduced
    2021-06-19 18:48:34,043 - INFO -     weight decay: none
    2021-06-19 18:48:34,044 - INFO -          l1decay: 0.0001
    2021-06-19 18:48:34,044 - INFO -          l2decay: 0.0001
    2021-06-19 18:48:34,044 - INFO - Getting loss function: ['softmax+bce']


    -------------------------------------------------------------------------------------------------------------------------------------
          Layer (type)                          Input Shape                                  Output Shape                   Param #    
    =====================================================================================================================================
       MyEmbeddingLayer-1                      [[2, 512, 10]]                                [2, 512, 10]                      0       
            Linear-1                           [[2, 512, 10]]                                [2, 512, 32]                     352      
             ReLU-1                            [[2, 512, 32]]                                [2, 512, 32]                      0       
           LayerNorm-1                         [[2, 512, 32]]                                [2, 512, 32]                     64       
            Dropout-1                          [[2, 512, 32]]                                [2, 512, 32]                      0       
         MyLinearTower-1                       [[2, 512, 10]]                                [2, 512, 32]                      0       
        PositionEncoder-1                      [[2, 512, 32]]                                [2, 512, 32]                      0       
           LayerNorm-2                         [[2, 512, 32]]                                [2, 512, 32]                     64       
            Linear-2                           [[2, 512, 32]]                                [2, 512, 32]                    1,056     
            Linear-3                           [[2, 512, 32]]                                [2, 512, 32]                    1,056     
            Linear-4                           [[2, 512, 32]]                                [2, 512, 32]                    1,056     
            Linear-5                           [[2, 512, 32]]                                [2, 512, 32]                    1,056     
      MultiHeadAttention-1    [[2, 512, 32], [2, 512, 32], [2, 512, 32], None]               [2, 512, 32]                      0       
            Dropout-3                          [[2, 512, 32]]                                [2, 512, 32]                      0       
           LayerNorm-3                         [[2, 512, 32]]                                [2, 512, 32]                     64       
            Linear-6                           [[2, 512, 32]]                                [2, 512, 32]                    1,056     
            Dropout-2                          [[2, 512, 32]]                                [2, 512, 32]                      0       
            Linear-7                           [[2, 512, 32]]                                [2, 512, 32]                    1,056     
            Dropout-4                          [[2, 512, 32]]                                [2, 512, 32]                      0       
    TransformerEncoderLayer-1                  [[2, 512, 32]]                                [2, 512, 32]                      0       
      TransformerEncoder-1                  [[2, 512, 32], None]                             [2, 512, 32]                      0       
          MyAttnTower-1                        [[2, 512, 32]]                                [2, 512, 32]                      0       
             LSTM-1                            [[2, 512, 32]]                  [[2, 512, 64], [[2, 2, 32], [2, 2, 32]]]     16,896     
          MyLSTMTower-1                        [[2, 512, 32]]                                [2, 512, 64]                      0       
            Conv1D-1                           [[2, 512, 64]]                                [2, 512, 32]                   10,272     
             ReLU-2                            [[2, 512, 32]]                                [2, 512, 32]                      0       
           LayerNorm-4                         [[2, 512, 32]]                                [2, 512, 32]                     64       
            Dropout-5                          [[2, 512, 32]]                                [2, 512, 32]                      0       
         MyConv1DTower-1                       [[2, 512, 64]]                                [2, 512, 32]                      0       
            Linear-8                           [[2, 512, 32]]                                [2, 512, 32]                    1,056     
             ReLU-3                            [[2, 512, 32]]                                [2, 512, 32]                      0       
           LayerNorm-5                         [[2, 512, 32]]                                [2, 512, 32]                     64       
            Dropout-6                          [[2, 512, 32]]                                [2, 512, 32]                      0       
            Linear-9                           [[2, 512, 32]]                                [2, 512, 32]                    1,056     
             ReLU-4                            [[2, 512, 32]]                                [2, 512, 32]                      0       
           LayerNorm-6                         [[2, 512, 32]]                                [2, 512, 32]                     64       
            Dropout-7                          [[2, 512, 32]]                                [2, 512, 32]                      0       
            Linear-10                          [[2, 512, 32]]                                [2, 512, 2]                      66       
         MyLinearTower-2                       [[2, 512, 32]]                                [2, 512, 2]                       0       
    =====================================================================================================================================
    Total params: 36,418
    Trainable params: 36,418
    Non-trainable params: 0
    -------------------------------------------------------------------------------------------------------------------------------------
    Input size (MB): 0.04
    Forward/backward pass size (MB): 9.73
    Params size (MB): 0.14
    Estimated Total Size (MB): 9.91
    -------------------------------------------------------------------------------------------------------------------------------------
    



```python
# è¯»å–æ•°æ®. æä¾›çš„æ•°æ®è¢«è½¬æ¢æˆäº†ä¸€ä¸ªdict, å­˜å‚¨ä¸ºpickleæ–‡ä»¶. 
# è¾“å…¥çŸ©é˜µä¸­æœ€åä¸¤åˆ—çš„æ•°æ®ä¸ºlinear_partition_cå’Œlinear_partition_vçš„é¢„æµ‹ç»“æœ
# Load data. The provided data are transfomed into a dict saved into a pickle file
# the last two columns in the input matrix are the predictions of linear_partition_c and linear_partition_v
midata = fp.get_midata(args)
train_data, valid_data = fp.train_test_split(midata, test_size=0.1)
```

    2021-06-19 18:48:34,050 - INFO - Loading data: work/data/train.pkl
    2021-06-19 18:48:34,101 - INFO -    # of data: 5000,  max seqlen: 500, user seq_length: [0, 512, -1]
    2021-06-19 18:48:34,102 - INFO -  residue fmt: vector, nn: 0, dbn: True, attr: False, genre: upp
    2021-06-19 18:48:34,121 - INFO - Selected 5000 data sets with length range: [0, 512, -1]



```python
# è®­ç»ƒæ¨¡å‹ï¼Œæœ€åçš„lossåº”è¯¥åœ¨[0.52, 0.53]åŒºé—´å†…. æ¯epoché‡Œè¿è¡Œ10æ¬¡validation check, å­˜å‚¨æœ€ä¼˜çš„.
# æ¯epochéœ€è¦äº”åˆ†é’Ÿå·¦å³(åœ¨CPUä¸Š)ï¼Œ è‡ªç„¶ç»“æŸéœ€è¦ï½20ä¸ªepoch
# Train the model - the final loss should be within 0.52 and 0.53.
# In each epoch, validation check is run 10 times, and the best model is saved.
# It takes about 5 minutes to complete one epoch. 
# A natural stop will go between 20 and 30 epochs
train_loss, valid_loss = fp.train(model, train_data, num_epochs=21, validate_callback = fp.func_partial(fp.validate_in_train, midata=valid_data, save_dir='./'))
# æ³¨1ï¼šè½¯æ ‡ç­¾çš„æƒ…å†µä¸‹ä¸èƒ½å¾—åˆ°0çš„äº¤å‰ç†µ
# Note1: zero cross-entropy is not possible with soft labels
# æ³¨2: æ²¡æœ‰åšç‰¹åˆ«çš„è¶…å‚æ•°ä¼˜åŒ–, åŸºæœ¬ä¸Šæ˜¯ç¼ºçœè®¾ç½®. å¦‚å‰é¢æåˆ°, æ›´å®½å’Œæ›´æ·±çš„ç½‘ç»œæ²¡æœ‰å¾—åˆ°æ›´å¥½çš„ç»“æœ.
# å› ä¸ºtrain_data and valid_dataå¾—åˆ°ç›¸è¿‘çš„ç»“æœ, æ²¡æœ‰ç”¨L1/L2 regularization
# ä¸€ä¸ªæ˜¾è‘—çš„é—®é¢˜æ˜¯æ•´ä½“æ”¶æ•›è¿‡å¿«, å¯èƒ½æ˜¯å› ä¸ºç½‘ç»œè¾ƒå°. åæœŸå·¥ä½œå¯ä»¥è°ƒæ•´learning_rate, dropoutç­‰ç­‰
# Note2: No particular efforts were made towards optimizer tweaking. Default values appeard to work fine.
# As mentioned earlier, wider and deeper nets didn't fare better, so were discarded in later trainings.
# No significant variations were observed between train_data and valid_data, so didn't use L1/L2 regularization.
# One conspicuous issue is that the model converges too quickly, future work may attempt to tune 
# hyperparameters such as learning rate, dropout, etc.
```


```python
ax = train_loss.plot.scatter('ibatch', 'loss')
ax = train_loss.groupby('epoch').mean().plot.scatter('ibatch', 'loss')
```


```python
# è¯»å–æœ€åä¸€ä¸ªcheckpointç›®å½• (å¿½ç•¥ä¼˜åŒ–å™¨state_dictè¯»å–é”™è¯¯)
# Load the last saved earlystop directory ï¼ˆignore the error in optimizer state_dict loading)
fp.state_dict_load(model, model.validate_hist.saved_dirs[-1])
# å¯ä»¥æ”¹åŠ¨æŸå¤±å‡½æ•°ï¼Œæ£€æµ‹mseæŸå¤±ï¼ˆå•ä¸ªæ¨¡å‹æœ€å¥½çš„ç»“æœï¼šï½0.20ï¼‰
# The loss_fn can be changed to softmax+mse to check the mse loss.
# (the best/lowest loss obtained from a single model was ~0.20)
args.loss_fn = ['softmax+mse']
model.loss_fn = fp.get_loss_fn(args)
valid_loss = fp.validate(model, valid_data, verbose=1, batch_size=64) # try a larger batch_size, should make no difference though
```


```python
# è¯»å–é¢„æµ‹æ•°æ®ï¼Œ å­˜å‚¨é¢„æµ‹ç»“æœ
# æäº¤çš„ç»“æœæ˜¯å¹³å‡äº†ä¸‰æ¬¡è¿è¡Œæœ€å¥½checkpointæ¨¡å‹ï¼Œ å®ƒä»¬åˆ†åˆ«å¾—åˆ°äº†0.24, 0.24, 0.242çš„sqrt(mse)æŸå¤±ï¼Œ å¹³å‡åå¾—åˆ°äº†0.238
# å¯æƒœå‰ä¸¤æ¬¡çš„checkpointæ²¡æœ‰è¢«ä¿å­˜ï¼Œ åªä¿å­˜äº†é¢„æµ‹çš„ç»“æœ.
# è™½ç„¶æ˜¯åŒä¸€ä¸ªç½‘ç»œæ¶æ„ï¼Œ å› ä¸ºæ¯æ¬¡è®­ç»ƒçš„train_test_splitæ˜¯éšæœºçš„ï¼Œ æ¨¡å‹å¹³å‡çš„æ•ˆæœå’Œcross_validateç›¸è¿‘
# Load the prediction data, and save the predicted results
# The submitted results are the average of the best checkpoints/earlystops from three independent trainings.
# Unfortunately the checkpoints for the first two were not kept, except for the predicted resultsã€‚
# As each training randomly splits the train and validation data, this model averaging approximates
# the effect/benefit of cross-validation.
predict_data = fp.get_midata(args, data_name='predict', seq_length=-1)
y_model, std_model = fp.predict(model, predict_data, save_dir='predict.files', batch_size=1)
```


```python
!zip -r9oT predict.files.zip predict.files/
```
